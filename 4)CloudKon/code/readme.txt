Step 1: Starting Instances, SQS and DynamoDB
This can be done from the local
Python strt_inst.py <number of Instances> <name of Instruction SQS> <name of Response SQS> <name of DynamoDB>
This tool will start the specified number of instances along with 2 SQS and 1 DynamoDB with the name specified
There is another tool to delete the instances and Queues
It is run as follows
Python terminate.py
This will terminate all the running instances and queues in the account. This is run just in case something goes wrong and u need to start making instances and queues again
17 instances, 1DynamoDB and 2 SQS are made using this tool
All the public DNS of instances are updated in the file worker
Step 2: Transferring Files 
The following files has to be transferred to the client using scp
client.py
wrkr.py
gnrtr.py
local.py
sender
worker
chk.py
animoto.py
animoto_client.py
animoto_wrkr.py
Step 3: Transferring files to the workers
Password less ssh is set up on every instance
Python-boto is installed on every instance
Then the script sender is used to push wrkr.py and animoto_wrkr.py to all the workers
Step 4: Generating instructions 
The Work_Load_File is generated by a command line tool
Python gnrtr.py <number of instructions> <instruction>
So if the tool is run as python gnrtr.py 10 sleep 10000 will generate a file wrkr with 1o sleep 10000 instructions
Step 5: Running the client 
The client is run using the command
Python client.py <Instruction Queue> <Work_Load_File>
The client will take values from the work load file, generates the ids , combines the id and the message and pushes them to the Instruction Queue 
Step 6: Running the Remote Workers
All the workers in the file worker is run using pssh at the same time
pssh -h wrkr -t 100000000 -l ubuntu -A -i "python wrkr.py <Instruction Queue> <DynamoDB> <Response Queue>

The worker is run using the command
Python wrkr.py <Instruction Queue> <DynamoDB> <Response Queue>
The workers will run till the instruction Queue is empty
The Response Queue is checked using the tool check.py
It is run using the following command
Python chk.py <Response Queue >
This will check the number of success messages in the given response queue
Step 7: Running the Local Worker
The worker is run using the following command
Python local.py <no of threads>
This will execute the number of instructions in the Work_Load_File and execute them using the number of threads specified
Step 8: Checking the Response Queue
The response queue is checked using the command
Python chk.py <Response Queue>
This will check the number of success messages in the response queue and this number is displayed 
Step 9: Generating Links
Animoto.py is run as follows
Python animoto.py <n>
Where n is the number of workers 
Step 10: Running the Animoto client
Animoto client is run as follows
Python animoto_client.py <instruction queue><Work load file>
This will make the client load the instructions form the work load file to the instruction queue
Step 11: Running the Animoto Worker
All the workers in the file worker is run using pssh at the same time
pssh -h wrkr -t 100000000 -l ubuntu -A -i "python animoto_wrkr.py <Instruction Queue> <DynamoDB> <Response Queue>

The worker is run using the command
Python animoto_wrkr.py <Instruction Queue> <DynamoDB> <Response Queue>
The workers will run till the instruction Queue is empty
